---
title: "Lab 09 - Grading the professor, Pt. 1"
author: Adam Paul
date: 5-7-2022
output: github_document
---

### Load packages and data

```{r load-packages, message=FALSE}
library(tidyverse) 
library(tidymodels)
library(openintro)
```

```{r putting the data in the environment}
evals <- evals

```


### Exercise 1

>Visualize the distribution of score. Is the distribution skewed? What does that tell you about how students rate courses? Is this what you expected to see? Why, or why not? Include any summary statistics and visualizations you use in your response.

```{r graphing score}
evals %>%
  ggplot(aes(x = score)) +
  geom_histogram()

summary(evals$score)
```

There is a negative skew, such that students tend to score professors relatively highly, mean being 4.175. This is pretty much what I expected, assuming that evals are required. Most people don't want to get their professor in trouble if they like them, so if they're forced to answer they probably answer "mostly good".



### Exercise 2

>Visualize and describe the relationship between score and the variable bty_avg, a professor’s average beauty rating.
  Hint: See the help page for the function at http://ggplot2.tidyverse.org/reference/index.html.

```{r score by beauty}
evals %>%
  ggplot(aes(x = bty_avg , y = score)) +
  geom_point()
```

Looking at it like this, I don't see any real relationship.

# Exercise 3

>Replot the scatterplot from Exercise 2, but this time use geom_jitter()? What does “jitter” mean? What was misleading about the initial scatterplot?

```{r}
evals %>%
  ggplot(aes(x= bty_avg , y= score)) +
  geom_point() +
  geom_jitter()
```

Jitter adds a bit of side-to-side variation to the points, to allow there to be more visibility of points that are stacked on one another. This was what was originally misleading, as the original didn't show how many points were present. It's more clear that attractive professors have less variability in their scores as compared to their less-attractive coworkers.


### Exercise 4

>Let’s see if the apparent trend in the plot is something more than natural variation. Fit a linear model called m_bty to predict average professor evaluation score by average beauty rating (bty_avg). Based on the regression output, write the linear model.


```{r lm for score}
m_bty <- lm(score ~ bty_avg, data=evals) 

print(m_bty)

summary(m_bty)
```

score = 3.88 + bty_avg*.067


### Exercise 5

>Replot your visualization from Exercise 3, and add the regression line to this plot in orange color. Turn off the shading for the uncertainty of the line.

```{r}
evals %>%
  ggplot(aes(x= bty_avg , y= score)) +
  geom_point() +
  geom_jitter() +
  geom_smooth( method= lm, se= FALSE, color = "orange")
```


### Exercise 6

>Interpret the slope of the linear model in context of the data.

The slope of the model is .067, which means that for every 1 point of attractiveness a professor's eval goes up .067 points

### Exercise 7

>Interpret the intercept of the linear model in context of the data. Comment on whether or not the intercept makes sense in this context.

The intercept is 3.88, which is the point at which the line crosses the y axis (or when x=0). That is, even if a professor has an attractiveness score of 0, they'd still have an average eval of 3.88. It's a little odd to consider what a 0 would be, and if we're talking about how people are usually perceived it might be more useful to know what the average attractiveness gets on their evals.

### Exercise 8

>Determine the R2 of the model and interpret it in context of the data.

```{r r squared}
summary(m_bty)

```

Multiple r-squared is .035. It tells us the overall variation that attractiveness (the only predictor loaded into the model) accounts for on score.


### Exercise 9

>Fit a new linear model called m_gen to predict average professor evaluation score based on gender of the professor. Based on the regression output, write the linear model and interpret the slope and intercept in context of the data.

```{r gender model}
m_gen <- lm(score ~ gender, data=evals)  

print(m_gen)

summary(m_gen)

```


### Exercise 10

>What is the equation of the line corresponding to male professors? What is it for female professors?

male:
score = 4.09 + (1*.1415)

female:
score = 4.09 + (0*.1415)

The difference should just be whether they are at the intercept or above, since it's dummy coded 0 and 1.


### Exercise 11

>Fit a new linear model called m_rank to predict average professor evaluation score based on rank of the professor. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data.

```{r rank-model}
m_rank <- lm(score ~ rank, data=evals) 

print(m_rank)

summary(m_rank)
```


Teaching:
score= 4.28 + (0) + (0)

Because teaching is the reverence class, it has neither of the slopes of the other to add to it. It is the score at "0" on rank. Adding the two 0's shows that these two slopes exist, but neither applies.

Tenure track:
score = 4.28 + (1*-.1297)= 4.15

Tenured:
score = 4.28 + (1*-.1452)= 4.13

The other two have their own slopes, so I dropped showing the other irrelevant slope.


### Exercise 12

>Create a new variable called rank_relevel where "tenure track" is the baseline level.

```{r rank relevel}
evals <- evals %>% 
  mutate(rank_relevel = relevel(rank, ref = "tenure track"))
```


### Exercise 13

>Fit a new linear model called m_rank_relevel to predict average professor evaluation score based on rank_relevel of the professor. This is the new (releveled) variable you created in Exercise 13. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data. Also determine and interpret the R2 of the model.

```{r relevel-model}
m_rank_relevel <- lm(score ~ rank_relevel, data=evals)
print(m_rank_relevel)
summary(m_rank_relevel)
```


Teaching:
score= 4.15 + (1*.1296)= 4.28

Tenure track:
score= 4.15 + (0) + (0)

Tenured:
score= 4.15 + (1*-.0155)= 4.13

What we see is that tenured professors have a slight decline in scores compared to the others, whereas teaching track have a slight improvement.

The R squared is .012, so it accounts for a small amount of the variance.


### Exercise 14

> Create another new variable called tenure_eligible that labels "teaching" faculty as "no" and labels "tenure track" and "tenured" faculty as "yes".


```{r tenure_eligible}
evals <- evals %>% 
  mutate(tenure_eligible = recode(rank, "tenure track" = "yes",
                                  "tenured" = "yes",
                                  "teaching" = "no"))
```


### Exercise 15

>Fit a new linear model called m_tenure_eligible to predict average professor evaluation score based on tenure_eligibleness of the professor. This is the new (regrouped) variable you created in Exercise 15. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data. Also determine and interpret the R2 of the model.

```{r tenure eligible model}
m_tenure_eligible <- lm(score ~ tenure_eligible, data=evals)

print(m_tenure_eligible)

summary(m_tenure_eligible)
```

score= 4.28 + (x*-.1406)

When you combine the tenure tracks together, they have a negative relationship with scores, which is predictable since earlier they were both negative.

R squared is .012, which again, should be the same as the last because it's essentially predicting the same thing.
